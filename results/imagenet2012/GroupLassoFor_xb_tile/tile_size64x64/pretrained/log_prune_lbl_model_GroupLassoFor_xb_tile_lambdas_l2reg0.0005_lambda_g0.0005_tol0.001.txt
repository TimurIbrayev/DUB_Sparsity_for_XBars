
*******************************************************************
==>> Run on: 2021-08-15 23:01:39
==>> Seed was set to: 1
==>> Dataset used: imagenet2012
==>> Batch size: 256
==>> Total training batches: 5005
==>> Total validation batches: 0
==>> Total testing batches: 196
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=512, out_features=1000, bias=True)
  )
)
Total prunable modules: 20
Pretrained model was loaded from checkpoint: ./results/imagenet2012/GroupLassoFor_xb_tile/xb_tile/checkpoint_model_GroupLassoFor_xb_tile_lambdas_l2reg0.0005_lambda_g0.0005_tol0.001.pth

prune_v0_lbl with the following parameters: 
  total_weights=11166912

==>>> MODEL EVAL ON VALIDATION SET | val loss: 1.277829, val acc: 0.6875
==>>> MODEL EVAL ON TEST SET | val loss: 1.277829, val acc: 0.6875

==>> Starting layer-by-layer pruning...
Pruning prunable layer with index 0 to the fixed target prune ratio [60.00]:
Pruned weights: 5645/9408 [60.00]
Pruning prunable layer with index 1 to the fixed target prune ratio [60.00]:
Pruned weights: 22118/36864 [60.00]
Pruning prunable layer with index 2 to the fixed target prune ratio [70.00]:
Pruned weights: 25805/36864 [70.00]
Pruning prunable layer with index 3 to the fixed target prune ratio [55.00]:
Pruned weights: 20275/36864 [55.00]
Pruning prunable layer with index 4 to the fixed target prune ratio [60.00]:
Pruned weights: 22118/36864 [60.00]
Pruning prunable layer with index 5 to the fixed target prune ratio [60.00]:
Pruned weights: 44237/73728 [60.00]
Pruning prunable layer with index 6 to the fixed target prune ratio [60.00]:
Pruned weights: 88474/147456 [60.00]
Pruning prunable layer with index 7 to the fixed target prune ratio [50.00]:
Pruned weights: 4096/8192 [50.00]
Pruning prunable layer with index 8 to the fixed target prune ratio [65.00]:
Pruned weights: 95846/147456 [65.00]
Pruning prunable layer with index 9 to the fixed target prune ratio [65.00]:
Pruned weights: 95846/147456 [65.00]
Pruning prunable layer with index 10 to the fixed target prune ratio [70.00]:
Pruned weights: 206438/294912 [70.00]
Pruning prunable layer with index 11 to the fixed target prune ratio [70.00]:
Pruned weights: 412877/589824 [70.00]
Pruning prunable layer with index 12 to the fixed target prune ratio [85.00]:
Pruned weights: 27852/32768 [85.00]
Pruning prunable layer with index 13 to the fixed target prune ratio [75.00]:
Pruned weights: 442368/589824 [75.00]
Pruning prunable layer with index 14 to the fixed target prune ratio [75.00]:
Pruned weights: 442368/589824 [75.00]
Pruning prunable layer with index 15 to the fixed target prune ratio [65.00]:
Pruned weights: 766772/1179648 [65.00]
Pruning prunable layer with index 16 to the fixed target prune ratio [75.00]:
Pruned weights: 1769472/2359296 [75.00]
Pruning prunable layer with index 17 to the fixed target prune ratio [70.00]:
Pruned weights: 91750/131072 [70.00]
Pruning prunable layer with index 18 to the fixed target prune ratio [75.00]:
Pruned weights: 1769472/2359296 [75.00]
Pruning prunable layer with index 19 to the fixed target prune ratio [75.00]:
Pruned weights: 1769473/2359296 [75.00]

==>> Total pruned weights: 8123302/11166912 [72.74]
==>> Total zeroes layerwise:
Prunable layer 0:	 5645/9408 [60.00]
Prunable layer 1:	 22118/36864 [60.00]
Prunable layer 2:	 25805/36864 [70.00]
Prunable layer 3:	 20275/36864 [55.00]
Prunable layer 4:	 22118/36864 [60.00]
Prunable layer 5:	 44237/73728 [60.00]
Prunable layer 6:	 88474/147456 [60.00]
Prunable layer 7:	 4096/8192 [50.00]
Prunable layer 8:	 95846/147456 [65.00]
Prunable layer 9:	 95846/147456 [65.00]
Prunable layer 10:	 206438/294912 [70.00]
Prunable layer 11:	 412877/589824 [70.00]
Prunable layer 12:	 27852/32768 [85.00]
Prunable layer 13:	 442368/589824 [75.00]
Prunable layer 14:	 442368/589824 [75.00]
Prunable layer 15:	 766772/1179648 [65.00]
Prunable layer 16:	 1769472/2359296 [75.00]
Prunable layer 17:	 91750/131072 [70.00]
Prunable layer 18:	 1769472/2359296 [75.00]
Prunable layer 19:	 1769473/2359296 [75.00]
==>> For tile size of (64, 64) and ADC resolution of 8 bits,
the following is the tile sparsity historgram,
based on PRUNED weights (= 0.0) after IRREGULAR LAYER-BY-LAYER pruning:
0.000:	1587
0.500:	1140
0.750:	0
0.875:	0
0.938:	0
0.969:	0
0.984:	0
0.992:	0

==>> Starting fine-tuning entire network, except classifier parameters...
==>> FINE_TUNE Optimizer settings: SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.01
    lr: 0.01
    momentum: 0.0
    nesterov: False
    weight_decay: 0.0
)
==>> FINE_TUNE LR scheduler type: <class 'torch.optim.lr_scheduler.MultiStepLR'>
==>> FINE_TUNE LR scheduler state: {'milestones': Counter({30: 1, 60: 1, 90: 1}), 'gamma': 0.1, 'base_lrs': [0.01], 'last_epoch': 0, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.01]}
==>> FINE_TUNE Number of training epochs: 120
==>>> FINE-TUNE | fine-tune epoch: 0, loss: 1.922073, acc: 0.5700, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 0, batch index: 196, val loss: 1.603967, val acc: 0.6148
==>>> FINE-TUNE | fine-tune epoch: 1, loss: 1.851429, acc: 0.5830, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 1, batch index: 196, val loss: 1.601612, val acc: 0.6156
==>>> FINE-TUNE | fine-tune epoch: 2, loss: 1.811414, acc: 0.5899, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 2, batch index: 196, val loss: 1.539514, val acc: 0.6287
==>>> FINE-TUNE | fine-tune epoch: 3, loss: 1.781310, acc: 0.5955, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 3, batch index: 196, val loss: 1.510058, val acc: 0.6357
==>>> FINE-TUNE | fine-tune epoch: 4, loss: 1.761895, acc: 0.5984, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 4, batch index: 196, val loss: 1.475930, val acc: 0.6428
==>>> FINE-TUNE | fine-tune epoch: 5, loss: 1.740699, acc: 0.6021, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 5, batch index: 196, val loss: 1.483335, val acc: 0.6392
==>>> FINE-TUNE | fine-tune epoch: 6, loss: 1.723901, acc: 0.6054, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 6, batch index: 196, val loss: 1.480169, val acc: 0.6412
==>>> FINE-TUNE | fine-tune epoch: 7, loss: 1.710968, acc: 0.6079, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 7, batch index: 196, val loss: 1.454752, val acc: 0.6464
==>>> FINE-TUNE | fine-tune epoch: 8, loss: 1.699489, acc: 0.6103, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 8, batch index: 196, val loss: 1.442080, val acc: 0.6476
==>>> FINE-TUNE | fine-tune epoch: 9, loss: 1.686094, acc: 0.6126, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 9, batch index: 196, val loss: 1.461802, val acc: 0.6446
==>>> FINE-TUNE | fine-tune epoch: 10, loss: 1.675058, acc: 0.6142, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 10, batch index: 196, val loss: 1.439687, val acc: 0.6481
==>>> FINE-TUNE | fine-tune epoch: 11, loss: 1.665779, acc: 0.6159, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 11, batch index: 196, val loss: 1.459349, val acc: 0.6452
==>>> FINE-TUNE | fine-tune epoch: 12, loss: 1.658320, acc: 0.6171, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 12, batch index: 196, val loss: 1.455945, val acc: 0.6463
==>>> FINE-TUNE | fine-tune epoch: 13, loss: 1.651283, acc: 0.6187, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 13, batch index: 196, val loss: 1.429880, val acc: 0.6520
==>>> FINE-TUNE | fine-tune epoch: 14, loss: 1.644150, acc: 0.6198, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 14, batch index: 196, val loss: 1.421041, val acc: 0.6539
==>>> FINE-TUNE | fine-tune epoch: 15, loss: 1.635649, acc: 0.6218, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 15, batch index: 196, val loss: 1.468269, val acc: 0.6446
==>>> FINE-TUNE | fine-tune epoch: 16, loss: 1.632675, acc: 0.6223, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 16, batch index: 196, val loss: 1.405616, val acc: 0.6567
==>>> FINE-TUNE | fine-tune epoch: 17, loss: 1.624880, acc: 0.6240, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 17, batch index: 196, val loss: 1.414469, val acc: 0.6573
==>>> FINE-TUNE | fine-tune epoch: 18, loss: 1.617520, acc: 0.6250, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 18, batch index: 196, val loss: 1.395168, val acc: 0.6578
==>>> FINE-TUNE | fine-tune epoch: 19, loss: 1.613716, acc: 0.6258, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 19, batch index: 196, val loss: 1.390186, val acc: 0.6610
==>>> FINE-TUNE | fine-tune epoch: 20, loss: 1.608641, acc: 0.6262, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 20, batch index: 196, val loss: 1.386924, val acc: 0.6617
==>>> FINE-TUNE | fine-tune epoch: 21, loss: 1.603420, acc: 0.6276, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 21, batch index: 196, val loss: 1.390163, val acc: 0.6598
==>>> FINE-TUNE | fine-tune epoch: 22, loss: 1.601091, acc: 0.6281, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 22, batch index: 196, val loss: 1.400621, val acc: 0.6587
==>>> FINE-TUNE | fine-tune epoch: 23, loss: 1.596454, acc: 0.6290, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 23, batch index: 196, val loss: 1.408554, val acc: 0.6579
==>>> FINE-TUNE | fine-tune epoch: 24, loss: 1.590967, acc: 0.6294, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 24, batch index: 196, val loss: 1.377987, val acc: 0.6641
==>>> FINE-TUNE | fine-tune epoch: 25, loss: 1.587079, acc: 0.6305, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 25, batch index: 196, val loss: 1.397150, val acc: 0.6588
==>>> FINE-TUNE | fine-tune epoch: 26, loss: 1.585530, acc: 0.6309, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 26, batch index: 196, val loss: 1.388999, val acc: 0.6626
==>>> FINE-TUNE | fine-tune epoch: 27, loss: 1.579752, acc: 0.6320, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 27, batch index: 196, val loss: 1.397543, val acc: 0.6596
==>>> FINE-TUNE | fine-tune epoch: 28, loss: 1.576342, acc: 0.6323, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 28, batch index: 196, val loss: 1.381404, val acc: 0.6616
==>>> FINE-TUNE | fine-tune epoch: 29, loss: 1.572728, acc: 0.6333, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 29, batch index: 196, val loss: 1.399264, val acc: 0.6574
==>>> FINE-TUNE | fine-tune epoch: 30, loss: 1.511863, acc: 0.6459, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 30, batch index: 196, val loss: 1.314621, val acc: 0.6787
==>>> FINE-TUNE | fine-tune epoch: 31, loss: 1.494184, acc: 0.6502, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 31, batch index: 196, val loss: 1.306688, val acc: 0.6799
==>>> FINE-TUNE | fine-tune epoch: 32, loss: 1.487900, acc: 0.6515, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 32, batch index: 196, val loss: 1.307563, val acc: 0.6801
==>>> FINE-TUNE | fine-tune epoch: 33, loss: 1.486077, acc: 0.6517, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 33, batch index: 196, val loss: 1.310999, val acc: 0.6799
==>>> FINE-TUNE | fine-tune epoch: 34, loss: 1.481411, acc: 0.6532, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 34, batch index: 196, val loss: 1.302985, val acc: 0.6809
==>>> FINE-TUNE | fine-tune epoch: 35, loss: 1.480750, acc: 0.6527, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 35, batch index: 196, val loss: 1.305318, val acc: 0.6808
==>>> FINE-TUNE | fine-tune epoch: 36, loss: 1.477673, acc: 0.6534, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 36, batch index: 196, val loss: 1.311048, val acc: 0.6803
==>>> FINE-TUNE | fine-tune epoch: 37, loss: 1.476479, acc: 0.6537, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 37, batch index: 196, val loss: 1.300347, val acc: 0.6824
==>>> FINE-TUNE | fine-tune epoch: 38, loss: 1.474850, acc: 0.6542, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 38, batch index: 196, val loss: 1.304104, val acc: 0.6811
==>>> FINE-TUNE | fine-tune epoch: 39, loss: 1.473962, acc: 0.6539, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 39, batch index: 196, val loss: 1.296920, val acc: 0.6825
==>>> FINE-TUNE | fine-tune epoch: 40, loss: 1.471379, acc: 0.6547, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 40, batch index: 196, val loss: 1.303727, val acc: 0.6801
==>>> FINE-TUNE | fine-tune epoch: 41, loss: 1.472306, acc: 0.6547, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 41, batch index: 196, val loss: 1.302451, val acc: 0.6811
==>>> FINE-TUNE | fine-tune epoch: 42, loss: 1.468874, acc: 0.6549, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 42, batch index: 196, val loss: 1.302555, val acc: 0.6812
==>>> FINE-TUNE | fine-tune epoch: 43, loss: 1.468608, acc: 0.6551, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 43, batch index: 196, val loss: 1.301520, val acc: 0.6806
==>>> FINE-TUNE | fine-tune epoch: 44, loss: 1.466955, acc: 0.6558, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 44, batch index: 196, val loss: 1.300271, val acc: 0.6812
==>>> FINE-TUNE | fine-tune epoch: 45, loss: 1.466957, acc: 0.6555, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 45, batch index: 196, val loss: 1.298432, val acc: 0.6818
==>>> FINE-TUNE | fine-tune epoch: 46, loss: 1.466342, acc: 0.6559, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 46, batch index: 196, val loss: 1.301211, val acc: 0.6813
==>>> FINE-TUNE | fine-tune epoch: 47, loss: 1.463980, acc: 0.6562, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 47, batch index: 196, val loss: 1.297396, val acc: 0.6826
==>>> FINE-TUNE | fine-tune epoch: 48, loss: 1.464254, acc: 0.6563, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 48, batch index: 196, val loss: 1.300949, val acc: 0.6811
==>>> FINE-TUNE | fine-tune epoch: 49, loss: 1.464097, acc: 0.6561, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 49, batch index: 196, val loss: 1.298696, val acc: 0.6826
==>>> FINE-TUNE | fine-tune epoch: 50, loss: 1.461665, acc: 0.6571, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 50, batch index: 196, val loss: 1.296357, val acc: 0.6825
==>>> FINE-TUNE | fine-tune epoch: 51, loss: 1.462617, acc: 0.6569, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 51, batch index: 196, val loss: 1.305500, val acc: 0.6798
==>>> FINE-TUNE | fine-tune epoch: 52, loss: 1.460600, acc: 0.6568, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 52, batch index: 196, val loss: 1.302514, val acc: 0.6801
==>>> FINE-TUNE | fine-tune epoch: 53, loss: 1.459664, acc: 0.6568, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 53, batch index: 196, val loss: 1.295429, val acc: 0.6821
==>>> FINE-TUNE | fine-tune epoch: 54, loss: 1.458498, acc: 0.6572, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 54, batch index: 196, val loss: 1.295160, val acc: 0.6823
==>>> FINE-TUNE | fine-tune epoch: 55, loss: 1.460128, acc: 0.6572, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 55, batch index: 196, val loss: 1.293693, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 56, loss: 1.459777, acc: 0.6577, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 56, batch index: 196, val loss: 1.296799, val acc: 0.6832
==>>> FINE-TUNE | fine-tune epoch: 57, loss: 1.458423, acc: 0.6573, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 57, batch index: 196, val loss: 1.297080, val acc: 0.6828
==>>> FINE-TUNE | fine-tune epoch: 58, loss: 1.456856, acc: 0.6577, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 58, batch index: 196, val loss: 1.294825, val acc: 0.6827
==>>> FINE-TUNE | fine-tune epoch: 59, loss: 1.456411, acc: 0.6582, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 59, batch index: 196, val loss: 1.295729, val acc: 0.6833
==>>> FINE-TUNE | fine-tune epoch: 60, loss: 1.452474, acc: 0.6587, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 60, batch index: 196, val loss: 1.292740, val acc: 0.6832
==>>> FINE-TUNE | fine-tune epoch: 61, loss: 1.452779, acc: 0.6580, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 61, batch index: 196, val loss: 1.294214, val acc: 0.6831
==>>> FINE-TUNE | fine-tune epoch: 62, loss: 1.449615, acc: 0.6593, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 62, batch index: 196, val loss: 1.292056, val acc: 0.6832
==>>> FINE-TUNE | fine-tune epoch: 63, loss: 1.447492, acc: 0.6599, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 63, batch index: 196, val loss: 1.292028, val acc: 0.6830
==>>> FINE-TUNE | fine-tune epoch: 64, loss: 1.448184, acc: 0.6594, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 64, batch index: 196, val loss: 1.295916, val acc: 0.6827
==>>> FINE-TUNE | fine-tune epoch: 65, loss: 1.449870, acc: 0.6596, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 65, batch index: 196, val loss: 1.288422, val acc: 0.6845
==>>> FINE-TUNE | fine-tune epoch: 66, loss: 1.449546, acc: 0.6591, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 66, batch index: 196, val loss: 1.293815, val acc: 0.6829
==>>> FINE-TUNE | fine-tune epoch: 67, loss: 1.447427, acc: 0.6594, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 67, batch index: 196, val loss: 1.292368, val acc: 0.6837
==>>> FINE-TUNE | fine-tune epoch: 68, loss: 1.447019, acc: 0.6595, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 68, batch index: 196, val loss: 1.288030, val acc: 0.6843
==>>> FINE-TUNE | fine-tune epoch: 69, loss: 1.448562, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 69, batch index: 196, val loss: 1.287560, val acc: 0.6838
==>>> FINE-TUNE | fine-tune epoch: 70, loss: 1.448316, acc: 0.6595, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 70, batch index: 196, val loss: 1.292106, val acc: 0.6838
==>>> FINE-TUNE | fine-tune epoch: 71, loss: 1.445967, acc: 0.6599, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 71, batch index: 196, val loss: 1.287731, val acc: 0.6851
==>>> FINE-TUNE | fine-tune epoch: 72, loss: 1.447020, acc: 0.6595, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 72, batch index: 196, val loss: 1.291420, val acc: 0.6841
==>>> FINE-TUNE | fine-tune epoch: 73, loss: 1.447543, acc: 0.6595, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 73, batch index: 196, val loss: 1.291168, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 74, loss: 1.445928, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 74, batch index: 196, val loss: 1.290050, val acc: 0.6845
==>>> FINE-TUNE | fine-tune epoch: 75, loss: 1.448625, acc: 0.6593, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 75, batch index: 196, val loss: 1.296195, val acc: 0.6824
==>>> FINE-TUNE | fine-tune epoch: 76, loss: 1.446310, acc: 0.6598, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 76, batch index: 196, val loss: 1.290474, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 77, loss: 1.445445, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 77, batch index: 196, val loss: 1.288540, val acc: 0.6842
==>>> FINE-TUNE | fine-tune epoch: 78, loss: 1.444269, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 78, batch index: 196, val loss: 1.293659, val acc: 0.6830
==>>> FINE-TUNE | fine-tune epoch: 79, loss: 1.446106, acc: 0.6599, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 79, batch index: 196, val loss: 1.291495, val acc: 0.6842
==>>> FINE-TUNE | fine-tune epoch: 80, loss: 1.446570, acc: 0.6600, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 80, batch index: 196, val loss: 1.289822, val acc: 0.6838
==>>> FINE-TUNE | fine-tune epoch: 81, loss: 1.446983, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 81, batch index: 196, val loss: 1.288213, val acc: 0.6852
==>>> FINE-TUNE | fine-tune epoch: 82, loss: 1.446898, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 82, batch index: 196, val loss: 1.289645, val acc: 0.6848
==>>> FINE-TUNE | fine-tune epoch: 83, loss: 1.445246, acc: 0.6599, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 83, batch index: 196, val loss: 1.292163, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 84, loss: 1.444549, acc: 0.6604, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 84, batch index: 196, val loss: 1.287701, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 85, loss: 1.446682, acc: 0.6600, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 85, batch index: 196, val loss: 1.286616, val acc: 0.6844
==>>> FINE-TUNE | fine-tune epoch: 86, loss: 1.444706, acc: 0.6600, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 86, batch index: 196, val loss: 1.290823, val acc: 0.6832
==>>> FINE-TUNE | fine-tune epoch: 87, loss: 1.445629, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 87, batch index: 196, val loss: 1.291491, val acc: 0.6844
==>>> FINE-TUNE | fine-tune epoch: 88, loss: 1.443629, acc: 0.6599, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 88, batch index: 196, val loss: 1.288419, val acc: 0.6852
==>>> FINE-TUNE | fine-tune epoch: 89, loss: 1.444232, acc: 0.6600, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 89, batch index: 196, val loss: 1.289408, val acc: 0.6845
==>>> FINE-TUNE | fine-tune epoch: 90, loss: 1.444182, acc: 0.6606, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 90, batch index: 196, val loss: 1.292184, val acc: 0.6835
==>>> FINE-TUNE | fine-tune epoch: 91, loss: 1.444863, acc: 0.6602, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 91, batch index: 196, val loss: 1.289249, val acc: 0.6840
==>>> FINE-TUNE | fine-tune epoch: 92, loss: 1.443889, acc: 0.6606, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 92, batch index: 196, val loss: 1.290621, val acc: 0.6850
==>>> FINE-TUNE | fine-tune epoch: 93, loss: 1.444179, acc: 0.6604, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 93, batch index: 196, val loss: 1.290641, val acc: 0.6844
==>>> FINE-TUNE | fine-tune epoch: 94, loss: 1.444527, acc: 0.6602, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 94, batch index: 196, val loss: 1.290358, val acc: 0.6846
==>>> FINE-TUNE | fine-tune epoch: 95, loss: 1.445435, acc: 0.6598, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 95, batch index: 196, val loss: 1.290528, val acc: 0.6846
==>>> FINE-TUNE | fine-tune epoch: 96, loss: 1.446232, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 96, batch index: 196, val loss: 1.289811, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 97, loss: 1.445030, acc: 0.6605, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 97, batch index: 196, val loss: 1.294204, val acc: 0.6836
==>>> FINE-TUNE | fine-tune epoch: 98, loss: 1.443674, acc: 0.6605, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 98, batch index: 196, val loss: 1.288282, val acc: 0.6847
==>>> FINE-TUNE | fine-tune epoch: 99, loss: 1.445910, acc: 0.6603, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 99, batch index: 196, val loss: 1.290703, val acc: 0.6848
==>>> FINE-TUNE | fine-tune epoch: 100, loss: 1.444399, acc: 0.6600, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 100, batch index: 196, val loss: 1.290151, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 101, loss: 1.443763, acc: 0.6601, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 101, batch index: 196, val loss: 1.286189, val acc: 0.6851
==>>> FINE-TUNE | fine-tune epoch: 102, loss: 1.445480, acc: 0.6604, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 102, batch index: 196, val loss: 1.292144, val acc: 0.6842
==>>> FINE-TUNE | fine-tune epoch: 103, loss: 1.444272, acc: 0.6604, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 103, batch index: 196, val loss: 1.290607, val acc: 0.6835
==>>> FINE-TUNE | fine-tune epoch: 104, loss: 1.446618, acc: 0.6599, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 104, batch index: 196, val loss: 1.291593, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 105, loss: 1.445408, acc: 0.6602, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 105, batch index: 196, val loss: 1.290012, val acc: 0.6841
==>>> FINE-TUNE | fine-tune epoch: 106, loss: 1.442866, acc: 0.6610, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 106, batch index: 196, val loss: 1.289763, val acc: 0.6841
==>>> FINE-TUNE | fine-tune epoch: 107, loss: 1.444156, acc: 0.6603, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 107, batch index: 196, val loss: 1.290117, val acc: 0.6846
==>>> FINE-TUNE | fine-tune epoch: 108, loss: 1.443078, acc: 0.6603, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 108, batch index: 196, val loss: 1.287587, val acc: 0.6854
==>>> FINE-TUNE | fine-tune epoch: 109, loss: 1.445010, acc: 0.6598, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 109, batch index: 196, val loss: 1.288427, val acc: 0.6845
==>>> FINE-TUNE | fine-tune epoch: 110, loss: 1.442689, acc: 0.6605, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 110, batch index: 196, val loss: 1.292165, val acc: 0.6840
==>>> FINE-TUNE | fine-tune epoch: 111, loss: 1.444773, acc: 0.6604, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 111, batch index: 196, val loss: 1.288757, val acc: 0.6831
==>>> FINE-TUNE | fine-tune epoch: 112, loss: 1.444770, acc: 0.6606, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 112, batch index: 196, val loss: 1.288887, val acc: 0.6843
==>>> FINE-TUNE | fine-tune epoch: 113, loss: 1.443895, acc: 0.6606, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 113, batch index: 196, val loss: 1.289079, val acc: 0.6847
==>>> FINE-TUNE | fine-tune epoch: 114, loss: 1.445054, acc: 0.6604, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 114, batch index: 196, val loss: 1.291326, val acc: 0.6837
==>>> FINE-TUNE | fine-tune epoch: 115, loss: 1.440869, acc: 0.6608, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 115, batch index: 196, val loss: 1.290450, val acc: 0.6839
==>>> FINE-TUNE | fine-tune epoch: 116, loss: 1.444651, acc: 0.6600, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 116, batch index: 196, val loss: 1.293767, val acc: 0.6840
==>>> FINE-TUNE | fine-tune epoch: 117, loss: 1.445518, acc: 0.6602, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 117, batch index: 196, val loss: 1.288588, val acc: 0.6841
==>>> FINE-TUNE | fine-tune epoch: 118, loss: 1.444946, acc: 0.6606, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 118, batch index: 196, val loss: 1.287020, val acc: 0.6846
==>>> FINE-TUNE | fine-tune epoch: 119, loss: 1.443953, acc: 0.6600, zeros: 8123302/11166912
==>>> CLEAN VALIDATE | epoch: 119, batch index: 196, val loss: 1.287411, val acc: 0.6852
Best val accuracy during fine-tuning: 68.54

==>> Total pruned weights: 8123302/11166912 [72.74]
==>> Total zeroes layerwise:
Prunable layer 0:	 5645/9408 [60.00]
Prunable layer 1:	 22118/36864 [60.00]
Prunable layer 2:	 25805/36864 [70.00]
Prunable layer 3:	 20275/36864 [55.00]
Prunable layer 4:	 22118/36864 [60.00]
Prunable layer 5:	 44237/73728 [60.00]
Prunable layer 6:	 88474/147456 [60.00]
Prunable layer 7:	 4096/8192 [50.00]
Prunable layer 8:	 95846/147456 [65.00]
Prunable layer 9:	 95846/147456 [65.00]
Prunable layer 10:	 206438/294912 [70.00]
Prunable layer 11:	 412877/589824 [70.00]
Prunable layer 12:	 27852/32768 [85.00]
Prunable layer 13:	 442368/589824 [75.00]
Prunable layer 14:	 442368/589824 [75.00]
Prunable layer 15:	 766772/1179648 [65.00]
Prunable layer 16:	 1769472/2359296 [75.00]
Prunable layer 17:	 91750/131072 [70.00]
Prunable layer 18:	 1769472/2359296 [75.00]
Prunable layer 19:	 1769473/2359296 [75.00]
==>> For tile size of (64, 64) and ADC resolution of 8 bits,
the following is the tile sparsity historgram,
based on PRUNED weights (= 0.0) after IRREGULAR LAYER-BY-LAYER pruning:
0.000:	1587
0.500:	1140
0.750:	0
0.875:	0
0.938:	0
0.969:	0
0.984:	0
0.992:	0

==>>> CLEAN VALIDATE ON TEST SET | val loss: 1.287587, val acc: 0.6854

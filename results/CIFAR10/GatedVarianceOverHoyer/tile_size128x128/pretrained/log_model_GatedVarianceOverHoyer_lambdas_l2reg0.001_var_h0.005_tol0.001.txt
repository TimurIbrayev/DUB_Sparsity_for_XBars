
*******************************************************************
==>> Run on: 2021-11-21 04:19:01
==>> Seed was set to: 1
==>> Dataset used: CIFAR10
==>> Batch size: 128
==>> Total training batches: 391
==>> Total validation batches: 0
==>> Total testing batches: 79
customizable_VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): ReLU(inplace=True)
    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): ReLU(inplace=True)
    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace=True)
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (19): ReLU(inplace=True)
    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
Pretrained model was loaded!
Total prunable modules: 8

==>> HoyerAndVariance with the following parameters: 
  tile_size=(128, 128)
  total_prune_layers=8
  total_weights=9217728
  total_tiles=564
  tol=0.001
  mean_over_hoyer_lambda=0.0
  variance_over_hoyer_lambda=0.005


==>> Starting training from scratch!
==>> Optimizer settings: SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.01
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001

Parameter Group 1
    dampening: 0
    initial_lr: 0.01
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)
==>> LR scheduler type: <class 'torch.optim.lr_scheduler.MultiStepLR'>
==>> LR scheduler state: {'milestones': Counter({50: 1, 100: 1, 150: 1}), 'gamma': 0.1, 'base_lrs': [0.01, 0.01], 'last_epoch': 0, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.01, 0.01]}
==>> Number of training epochs: 160
==>>> TRAIN-PRUNE | train epoch: 0, loss: 125.471087, acc: 0.1557, almost zeros: 4401649/9217728
==>>> cls loss: 2.275218	 variance_over_hoyer loss: 123.195868	
==>>> CLEAN VALIDATE | epoch: 0, batch index: 79, val loss: 2.068210, val acc: 0.1805
==>>> TRAIN-PRUNE | train epoch: 1, loss: 52.773393, acc: 0.2289, almost zeros: 4950764/9217728
==>>> cls loss: 1.932954	 variance_over_hoyer loss: 50.840439	
==>>> CLEAN VALIDATE | epoch: 1, batch index: 79, val loss: 1.746532, val acc: 0.2984
==>>> TRAIN-PRUNE | train epoch: 2, loss: nan, acc: 0.2542, almost zeros: 367643/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 2, batch index: 79, val loss: nan, val acc: 0.1000
==>>> TRAIN-PRUNE | train epoch: 3, loss: nan, acc: 0.1000, almost zeros: 397091/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 3, batch index: 79, val loss: nan, val acc: 0.1000
==>>> TRAIN-PRUNE | train epoch: 4, loss: nan, acc: 0.1000, almost zeros: 406381/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 4, batch index: 79, val loss: nan, val acc: 0.1000
==>>> TRAIN-PRUNE | train epoch: 5, loss: nan, acc: 0.1000, almost zeros: 412213/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 5, batch index: 79, val loss: nan, val acc: 0.1000
==>>> TRAIN-PRUNE | train epoch: 6, loss: nan, acc: 0.1000, almost zeros: 416828/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 6, batch index: 79, val loss: nan, val acc: 0.1000
==>>> TRAIN-PRUNE | train epoch: 7, loss: nan, acc: 0.1000, almost zeros: 420757/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 7, batch index: 79, val loss: nan, val acc: 0.1000
==>>> TRAIN-PRUNE | train epoch: 8, loss: nan, acc: 0.1000, almost zeros: 424410/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 8, batch index: 79, val loss: nan, val acc: 0.1000
==>>> TRAIN-PRUNE | train epoch: 9, loss: nan, acc: 0.1000, almost zeros: 427711/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 9, batch index: 79, val loss: nan, val acc: 0.1000

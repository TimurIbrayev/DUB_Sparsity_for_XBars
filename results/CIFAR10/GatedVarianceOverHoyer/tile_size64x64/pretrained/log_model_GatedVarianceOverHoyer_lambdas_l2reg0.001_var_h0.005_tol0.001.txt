
*******************************************************************
==>> Run on: 2020-12-23 22:24:54
==>> Seed was set to: 1
==>> Dataset used: CIFAR10
==>> Batch size: 128
==>> Total training batches: 391
==>> Total validation batches: 0
==>> Total testing batches: 79
customizable_VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): ReLU(inplace=True)
    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): ReLU(inplace=True)
    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace=True)
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (19): ReLU(inplace=True)
    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=512, out_features=512, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=512, out_features=10, bias=True)
  )
)
Pretrained model was loaded!
Total prunable modules: 8

==>> HoyerAndVariance with the following parameters: 
  tile_size=(64, 64)
  total_prune_layers=8
  total_weights=9217728
  total_tiles=2251
  tol=0.001
  variance_over_hoyer_lambda=0.005


==>> Starting training from scratch!
==>> Optimizer settings: SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.01
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001

Parameter Group 1
    dampening: 0
    initial_lr: 0.01
    lr: 0.01
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)
==>> LR scheduler type: <class 'torch.optim.lr_scheduler.MultiStepLR'>
==>> LR scheduler state: {'milestones': Counter({50: 1, 100: 1, 150: 1}), 'gamma': 0.1, 'base_lrs': [0.01, 0.01], 'last_epoch': 0, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.01, 0.01]}
==>> Number of training epochs: 160
==>>> TRAIN-PRUNE | train epoch: 0, loss: 153.464074, acc: 0.1679, almost zeros: 4155689/9217728
==>>> cls loss: 2.305873	 variance_over_hoyer loss: 151.158201	
==>>> CLEAN VALIDATE | epoch: 0, batch index: 79, val loss: 1.996604, val acc: 0.1927
==>>> TRAIN-PRUNE | train epoch: 1, loss: 58.946059, acc: 0.2038, almost zeros: 4687080/9217728
==>>> cls loss: 1.968652	 variance_over_hoyer loss: 56.977407	
==>>> CLEAN VALIDATE | epoch: 1, batch index: 79, val loss: 1.891710, val acc: 0.2298
==>>> TRAIN-PRUNE | train epoch: 2, loss: 50.089731, acc: 0.2541, almost zeros: 5007765/9217728
==>>> cls loss: 1.857535	 variance_over_hoyer loss: 48.232196	
==>>> CLEAN VALIDATE | epoch: 2, batch index: 79, val loss: 1.740976, val acc: 0.3313
==>>> TRAIN-PRUNE | train epoch: 3, loss: nan, acc: 0.3237, almost zeros: 0/9217728
==>>> cls loss: nan	 variance_over_hoyer loss: nan	
==>>> CLEAN VALIDATE | epoch: 3, batch index: 79, val loss: nan, val acc: 0.1000
